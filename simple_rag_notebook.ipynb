{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "26e657ed",
      "metadata": {
        "id": "26e657ed"
      },
      "source": [
        "# 1. Install and Import Required Libraries\n",
        "In this section, we will install and import the necessary libraries for working with FAISS, OpenAI, and PDF processing.\n",
        "\n",
        "- **faiss**: For creating and querying the vector store\n",
        "- **openai**: For generating embeddings and chatting with the model\n",
        "- **numpy**: For handling numerical data\n",
        "- **PyPDF2**: For reading and processing PDF documents\n",
        "\n",
        "You may need to run the installation cell below if these packages are not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a91770f",
      "metadata": {
        "id": "4a91770f"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if running in a new environment)\n",
        "!pip install faiss-cpu openai numpy PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba2beef",
      "metadata": {
        "id": "8ba2beef"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import faiss\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74b67565",
      "metadata": {
        "id": "74b67565"
      },
      "source": [
        "# 2. Set Up OpenAI API Key in Google Colab\n",
        "\n",
        "To use OpenAI's services securely in Google Colab, we'll store the API key in Colab's secrets manager. This is more secure than having the API key directly in your notebook.\n",
        "\n",
        "1. Click on the 'Files' icon in the left sidebar\n",
        "2. Click on the 'folder' icon to show all files\n",
        "3. Click on the 'key' icon to open the Secrets manager\n",
        "4. Add a new secret with:\n",
        "   - Name: `OPENAI_API_KEY`\n",
        "   - Value: Your OpenAI API key from https://platform.openai.com/account/api-keys\n",
        "\n",
        "The next cell will retrieve the key from Colab's secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92749f18",
      "metadata": {
        "id": "92749f18"
      },
      "outputs": [],
      "source": [
        "# Set up OpenAI API key from Google Colab secrets\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    print(\"OpenAI client successfully initialized with API key from Colab secrets!\")\n",
        "except Exception as e:\n",
        "    print(\"Error: Could not load OpenAI API key from Colab secrets.\")\n",
        "    print(\"Please make sure you've added your API key to the Colab secrets manager.\")\n",
        "    print(\"Instructions are in the markdown cell above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b75c7694",
      "metadata": {
        "id": "b75c7694"
      },
      "source": [
        "# 3. Generate Embeddings Using OpenAI SDK\n",
        "We will use OpenAI's embedding model to convert PDF document content into numerical vectors. These embeddings will be used to populate our FAISS vector store.\n",
        "\n",
        "First, we'll read and process a PDF file, splitting it into chunks, and then generate embeddings for each chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9568de31",
      "metadata": {
        "id": "9568de31"
      },
      "outputs": [],
      "source": [
        "# Function to read PDF and split into chunks\n",
        "def read_pdf_and_split(file_path, chunk_size=1000):\n",
        "    reader = PdfReader(file_path)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    # Extract text from each page\n",
        "    for page in reader.pages:\n",
        "        text = page.extract_text()\n",
        "        words = text.split()\n",
        "\n",
        "        # Create chunks of approximately chunk_size characters\n",
        "        for word in words:\n",
        "            if len(current_chunk) + len(word) + 1 <= chunk_size:\n",
        "                current_chunk += word + \" \"\n",
        "            else:\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = word + \" \"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Function to generate embeddings\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Read and process the PDF file\n",
        "pdf_path = \"ncert_physics.pdf\"  # Replace with your PDF file path\n",
        "chunks = read_pdf_and_split(pdf_path)\n",
        "print(f\"Document split into {len(chunks)} chunks\")\n",
        "\n",
        "# Generate embeddings for each chunk\n",
        "chunk_embeddings = []\n",
        "for chunk in chunks:\n",
        "    embedding = get_embedding(chunk)\n",
        "    chunk_embeddings.append(embedding)\n",
        "\n",
        "print(\"Embeddings generated successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056b9df9",
      "metadata": {
        "id": "056b9df9"
      },
      "source": [
        "# 4. Create and Populate FAISS Vector Store\n",
        "Now that we have embeddings for our documents, we will create a FAISS index and add these embeddings to it. This will allow us to efficiently search for similar documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04cb343",
      "metadata": {
        "id": "a04cb343"
      },
      "outputs": [],
      "source": [
        "# Create FAISS index and add embeddings\n",
        "embedding_dim = len(chunk_embeddings[0])\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# Convert embeddings to numpy array and add to index\n",
        "embeddings = np.array(chunk_embeddings).astype('float32')\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} vectors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10eddf6e",
      "metadata": {
        "id": "10eddf6e"
      },
      "source": [
        "# 5. Query the FAISS Index\n",
        "Let's see how to query the FAISS index. We'll take a new text, generate its embedding, and find the most similar documents in our vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9cf1723",
      "metadata": {
        "id": "f9cf1723"
      },
      "outputs": [],
      "source": [
        "# Query the FAISS index\n",
        "query_text = \"Explain the physical significance of electric field?\"  # Replace with your question\n",
        "query_embedding = np.array([get_embedding(query_text)]).astype('float32')\n",
        "\n",
        "k = 3  # Number of nearest chunks to retrieve\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "print(\"Query:\", query_text)\n",
        "print(\"\\nMost relevant chunks:\")\n",
        "for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
        "    print(f\"\\nChunk {i+1} (distance: {dist:.2f}):\")\n",
        "    print(chunks[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62caf723",
      "metadata": {
        "id": "62caf723"
      },
      "source": [
        "# 6. Integrate Chat with OpenAI Using Retrieved Context\n",
        "We can use the most relevant documents retrieved from the FAISS index as context for a chat interaction with OpenAI's language model. This helps the model provide more informed and accurate responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d356f3",
      "metadata": {
        "id": "f9d356f3"
      },
      "outputs": [],
      "source": [
        "# Use retrieved chunks as context for chat\n",
        "context_chunks = \"\\n\\n\".join([chunks[i] for i in indices[0]])\n",
        "\n",
        "chat_prompt = f\"\"\"Context from the document:\\n{context_chunks}\\n\\nBased on the above context from the document, please answer this question: {query_text}\\nAnswer:\"\"\"\n",
        "\n",
        "# Strictly use GPT-5 as requested\n",
        "model = \"gpt-4o\"\n",
        "print(f\"Using strict model: {model}\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided document context.\"},\n",
        "        {\"role\": \"user\", \"content\": chat_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Chatbot response:\")\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}